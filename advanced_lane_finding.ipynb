{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Lane Finding Project\n",
    "\n",
    "The goals / steps of this project are the following:\n",
    "\n",
    "* Compute the camera calibration matrix and distortion coefficients given a set of chessboard images.\n",
    "* Apply a distortion correction to raw images.\n",
    "* Use color transforms, gradients, etc., to create a thresholded binary image.\n",
    "* Apply a perspective transform to rectify binary image (\"birds-eye view\").\n",
    "* Detect lane pixels and fit to find the lane boundary.\n",
    "* Determine the curvature of the lane and vehicle position with respect to center.\n",
    "* Warp the detected lane boundaries back onto the original image.\n",
    "* Output visual display of the lane boundaries and numerical estimation of lane curvature and vehicle position.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Import libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import ntpath\n",
    "import math\n",
    "import pickle\n",
    "import os\n",
    "import pandas as pd\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Create utils."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Util:\n",
    "    \n",
    "    \n",
    "    def get_fname(path):\n",
    "        \n",
    "        _, tail = ntpath.split(path)\n",
    "        \n",
    "        return tail\n",
    "    \n",
    "    \n",
    "    def set_output(number, output = None):\n",
    "        \n",
    "        if output == 'qt':\n",
    "            \n",
    "            %matplotlib qt\n",
    "            fontsize = 10\n",
    "            nrows = int(math.sqrt(number))\n",
    "            ncols = number//nrows\n",
    "            figure, axes = plt.subplots(nrows, ncols, figsize=(10*ncols, 6*math.ceil(number/ncols)))\n",
    "            \n",
    "            return output, figure, axes, fontsize, ncols\n",
    "        \n",
    "        elif output == 'inline':\n",
    "            \n",
    "            %matplotlib inline\n",
    "            fontsize = 18\n",
    "            ncols = 2\n",
    "            figure, axes = plt.subplots(number//2,ncols, figsize=(10*ncols, 6*number//2))\n",
    "            \n",
    "            return output, figure, axes, fontsize, ncols\n",
    "        \n",
    "        elif output != None and output != '' and output[-1] != '/':\n",
    "            \n",
    "            output += '/'\n",
    "            \n",
    "            return output, None, None, None, None\n",
    "    \n",
    "    \n",
    "    def show_output(output, figure, title):\n",
    "        \n",
    "        if output == 'qt':\n",
    "            \n",
    "            figure.canvas.set_window_title(title)\n",
    "            figure.patch.set_facecolor('xkcd:gray')\n",
    "            plt.subplots_adjust(top=0.95, bottom=0.05, hspace=0.3, wspace=0.3)\n",
    "            \n",
    "        elif output == 'inline':\n",
    "            \n",
    "            figure.suptitle(title, fontsize=18)\n",
    "            plt.subplots_adjust(top=4, hspace=4)\n",
    "            plt.tight_layout()\n",
    "            \n",
    "        \n",
    "        if output == 'inline' or output == 'qt':\n",
    "            \n",
    "            plt.show()\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Create calibration tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Camera:\n",
    "        \n",
    "        \n",
    "    def __init__(self, calibrationset=None):\n",
    "        \n",
    "        if calibrationset == None: \n",
    "            \n",
    "            dist_pickle = pickle.load(open(\"camera_calibration.p\", \"rb\"))\n",
    "            self.mtx = dist_pickle[\"mtx\"]\n",
    "            self.dist = dist_pickle[\"dist\"]\n",
    "            self.images = []\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            self.mtx = []\n",
    "            self.dist = []\n",
    "            self.images = glob.glob(calibrationset)\n",
    "    \n",
    "    \n",
    "    def calibrate(self, output=None):\n",
    "        \n",
    "        if (len(self.images) == 0):\n",
    "            \n",
    "            return False;\n",
    "        \n",
    "        objp = np.zeros((6*9,3), np.float32)\n",
    "        objp[:,:2] = np.mgrid[0:9,0:6].T.reshape(-1,2)      \n",
    "        counter = 0 \n",
    "        objpoints = [] # 3d points in real world space\n",
    "        imgpoints = [] # 2d points in image plane.\n",
    "        testimages = []\n",
    "        \n",
    "        output, figure, axes, fontsize, ncols = Util.set_output(len(self.images), output)\n",
    "        \n",
    "        for fname in self.images:\n",
    "            \n",
    "            img = cv2.imread(fname)\n",
    "            gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "            ret, corners = cv2.findChessboardCorners(gray, (9,6),None)\n",
    "            if ret == True:\n",
    "                objpoints.append(objp)\n",
    "                imgpoints.append(corners)\n",
    "\n",
    "                # Draw and display the corners\n",
    "                img = cv2.drawChessboardCorners(img, (9,6), corners, ret)\n",
    "                if output == 'inline' or output == 'qt':\n",
    "                    \n",
    "                    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "                    axes[counter//ncols][counter%ncols].set_title(Util.get_fname(fname), fontsize=fontsize)\n",
    "                    axes[counter//ncols][counter%ncols].imshow(img);\n",
    "                    counter += 1\n",
    "                    \n",
    "                elif output != None:\n",
    "                    \n",
    "                    cv2.imwrite(output+'corners_'+Util.get_fname(fname), img)\n",
    "            else:\n",
    "                testimages.append(fname)\n",
    "                \n",
    "        if (len(imgpoints) == 0):\n",
    "            \n",
    "            return False\n",
    "        \n",
    "        ret, self.mtx, self.dist, _, _ = cv2.calibrateCamera(objpoints, imgpoints, img.shape[1::-1], None, None)\n",
    "        \n",
    "        # Return value from calibrateCamera is more than 1 which suggest poor quality calibration\n",
    "        if (ret > 1.1):\n",
    "            \n",
    "            return False\n",
    "        \n",
    "        dist_pickle = {}\n",
    "        dist_pickle[\"mtx\"] = self.mtx\n",
    "        dist_pickle[\"dist\"] = self.dist\n",
    "        pickle.dump(dist_pickle, open(\"camera_calibration.p\", \"wb\"))\n",
    "        \n",
    "        if (output == None):\n",
    "            \n",
    "            return True\n",
    "        \n",
    "        if (len(testimages) == 0):\n",
    "            \n",
    "            testimages.append(images[0])\n",
    "        \n",
    "        img = cv2.imread(testimages[0])\n",
    "        dst = cv2.undistort(img, self.mtx, self.dist, None, self.mtx)\n",
    "        if output == 'inline' or output == 'qt':\n",
    "            \n",
    "            counter += 1\n",
    "            axes[counter//ncols][counter%ncols].set_title(\"Test image\", fontsize=fontsize)\n",
    "            axes[counter//ncols][counter%ncols].imshow(img);\n",
    "            counter += 1\n",
    "            axes[counter//ncols][counter%ncols].set_title(\"Undistorted image\", fontsize=fontsize)\n",
    "            axes[counter//ncols][counter%ncols].imshow(dst)\n",
    "            \n",
    "            Util.show_output(output, figure, 'Calibration')\n",
    "            \n",
    "        elif output != None:\n",
    "\n",
    "            cv2.imwrite(output + 'corners_undistort_' + Util.get_fname(testimages[0]), dst)\n",
    "\n",
    "            \n",
    "    def undistort(self, img = [], fname=None, output=None):\n",
    "        \n",
    "        if len(self.mtx) == 0 or len(self.dist) == 0:\n",
    "            return None\n",
    "        if fname != None and len(img) == 0:\n",
    "            img = cv2.imread(fname)\n",
    "        if len(img) == 0:\n",
    "            return None\n",
    "        undistort = cv2.undistort(img, self.mtx, self.dist, None, self.mtx) \n",
    "        if output != None and output != '' and output[-1] != '/':\n",
    "            output += '/'\n",
    "        if output != None:\n",
    "            cv2.imwrite(output + 'undistort_' + Util.get_fname(fname), undistort)\n",
    "            \n",
    "        return img, undistort\n",
    "    \n",
    "    \n",
    "    def test(self, files, output):\n",
    "        \n",
    "        output, figure, axes, fontsize, ncols = Util.set_output(len(files)*2, output)\n",
    "        \n",
    "        counter = 0\n",
    "        \n",
    "        for file in files:\n",
    "            \n",
    "            original, undistort = camera.undistort(fname=file, output=output)\n",
    "            \n",
    "            if output == 'qt' or output == 'inline':\n",
    "                original = cv2.cvtColor(original, cv2.COLOR_BGR2RGB)\n",
    "                axes[counter//ncols][counter%ncols].set_title(Util.get_fname(file), fontsize=fontsize)\n",
    "                axes[counter//ncols][counter%ncols].imshow(original)\n",
    "                counter+=1\n",
    "                undistort = cv2.cvtColor(undistort, cv2.COLOR_BGR2RGB)\n",
    "                axes[counter//ncols][counter%ncols].set_title('Undistorted Image', fontsize=fontsize)\n",
    "                axes[counter//ncols][counter%ncols].imshow(undistort)\n",
    "                counter+=1\n",
    "            \n",
    "        Util.show_output(output, figure, 'Original vs. Undistorted Test Images')\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Make camera calibration based on calibration images set and then undistort test images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob('output_images/undistort*')\n",
    "files.extend(glob.glob('output_images/corners*'))\n",
    "for file in files:\n",
    "    os.remove(file)\n",
    "\n",
    "camera = Camera('camera_cal/calibration*.jpg')\n",
    "camera.calibrate('output_images')\n",
    "files = glob.glob('test_images/*')\n",
    "\n",
    "camera.test(files, 'output_images')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Create transform tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transform:\n",
    "    \n",
    "    # Perspective transformation parameters\n",
    "    src = np.float32([(230, 690), (545, 480), (735, 480), (1050, 690)])\n",
    "    dst = np.float32([(230, 720), (230,   0), (1050,  0), (1050, 720)])\n",
    "    \n",
    "    \n",
    "    def read(fname):\n",
    "        \n",
    "        return cv2.cvtColor(cv2.imread(fname), cv2.COLOR_BGR2RGB);\n",
    "    \n",
    "    \n",
    "    def write(binary, fname=None, output=None):\n",
    "        \n",
    "        if output != None and output != '' and output[-1] != '/':\n",
    "            output += '/'\n",
    "        elif output == None:\n",
    "            output = ''\n",
    "        if fname != None:\n",
    "            cv2.imwrite(output+fname, binary*255)\n",
    "    \n",
    "    \n",
    "    def abs_threshold(img, fname=None, output=None, orient='x', sobel_kernel=3, thresh=(0, 255)):\n",
    "        \n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "        if orient == 'x':\n",
    "            sobel = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=sobel_kernel)\n",
    "        elif orient == 'y':\n",
    "            sobel = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=sobel_kernel)\n",
    "        else:\n",
    "            return None\n",
    "        abs_sobel = np.absolute(sobel)\n",
    "        scaled_sobel = np.uint8(255*abs_sobel/np.max(abs_sobel))\n",
    "        binary = np.zeros_like(scaled_sobel)\n",
    "        binary[(scaled_sobel >= thresh[0]) & (scaled_sobel <= thresh[1])] = 1\n",
    "        if fname != None:\n",
    "            Transform.write(binary, 'transform_abs_'+fname, output)\n",
    "            \n",
    "        return binary\n",
    "    \n",
    "    \n",
    "    def mag_threshold(img, fname=None, output=None, sobel_kernel=3, thresh=(0, 255)):\n",
    "        \n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "        sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=sobel_kernel)\n",
    "        sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=sobel_kernel)\n",
    "        abs_sobelxy = np.sqrt(np.power(sobelx,2) + np.power(sobely, 2))\n",
    "        scaled_sobel = np.uint8(255*abs_sobelxy/np.max(abs_sobelxy))\n",
    "        binary = np.zeros_like(scaled_sobel)\n",
    "        binary[(scaled_sobel >= thresh[0]) & (scaled_sobel <= thresh[1])] = 1\n",
    "        if fname != None:\n",
    "            Transform.write(binary, 'transform_mag_'+fname, output)\n",
    "            \n",
    "        return binary\n",
    "    \n",
    "    \n",
    "    def dir_threshold(img, fname=None, output=None, sobel_kernel=3, thresh=(0, np.pi/2)):\n",
    "        \n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "        sobelx = cv2.Sobel(img, cv2.CV_64F, 1, 0, ksize=sobel_kernel)\n",
    "        sobely = cv2.Sobel(img, cv2.CV_64F, 0, 1, ksize=sobel_kernel)\n",
    "        abs_sobelx = np.absolute(sobelx)\n",
    "        abs_sobely = np.absolute(sobely)\n",
    "        direction = np.arctan2(abs_sobely, abs_sobelx)\n",
    "        binary = np.zeros_like(direction)\n",
    "        binary[(direction >= thresh[0]) & (direction <= thresh[1])] = 1\n",
    "        if fname != None:\n",
    "            Transform.write(binary, 'transform_dir_'+fname, output)\n",
    "            \n",
    "        return binary\n",
    "    \n",
    "    \n",
    "    def gray_threshold(img, fname=None, output=None, thresh=(0, 255)):\n",
    "        \n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "        binary = np.zeros_like(gray)\n",
    "        binary[(gray > thresh[0]) & (gray <= thresh[1])] = 1\n",
    "        if fname != None:\n",
    "            Transform.write(binary, 'transform_gray_'+fname, output)\n",
    "            \n",
    "        return binary\n",
    "    \n",
    "    \n",
    "    def color_threshold(img, fname=None, output=None, space='rgb', select='r', thresh=(0, 255)):\n",
    "        \n",
    "        if space == 'hls':\n",
    "            image = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)\n",
    "        elif space == 'hsv':\n",
    "            image = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)\n",
    "        elif output != 'rgb':\n",
    "            return None\n",
    "        C = image[:,:,space.find(select)]\n",
    "        binary = np.zeros_like(C)\n",
    "        binary[(C > thresh[0]) & (C <= thresh[1])] = 1\n",
    "        if fname != None:\n",
    "            Transform.write(binary, 'transform_'+space+'_'+select+'_'+fname, output)\n",
    "            \n",
    "        return binary\n",
    "    \n",
    "    \n",
    "    def canny(img, fname=None, output=None, kernel_size=3):\n",
    "        \n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "        med = np.median(gray)\n",
    "        image = cv2.GaussianBlur(gray, (kernel_size, kernel_size), 0)\n",
    "        image = cv2.Canny(image, (2/3)*med, (3/4)*med)\n",
    "        binary = np.zeros_like(image)\n",
    "        binary[(image >= 1)] = 1\n",
    "        if fname != None:\n",
    "            Transform.write(binary, 'transform_canny_'+fname, output)\n",
    "            \n",
    "        return binary\n",
    "        \n",
    "        \n",
    "    def combine(img, fname=None, output=None):\n",
    "        \n",
    "        binary = np.zeros_like(img[0])\n",
    "        for image in img:\n",
    "            binary[image == 1] = 1 \n",
    "        if fname != None:\n",
    "            Transform.write(binary, 'transform_combine_'+fname, output)\n",
    "            \n",
    "        return binary\n",
    "    \n",
    "    \n",
    "    def unwarp(img, fname=None, output=None):\n",
    "        \n",
    "        M = cv2.getPerspectiveTransform(Transform.src, Transform.dst)\n",
    "        \n",
    "        binary = cv2.warpPerspective(img, M, img.shape[1::-1], flags=cv2.INTER_LINEAR)\n",
    "        if fname != None:\n",
    "            Transform.write(binary, 'transform_unwarp_'+fname, output)\n",
    "            \n",
    "        return binary\n",
    "    \n",
    "    \n",
    "    def warp(img, fname=None, output=None):\n",
    "\n",
    "        M = cv2.getPerspectiveTransform(Transform.dst, Transform.src)\n",
    "        \n",
    "        # Warp the blank back to original image space using inverse perspective matrix (Minv)\n",
    "        result = cv2.warpPerspective(img, M, img.shape[1::-1], flags=cv2.INTER_LINEAR)\n",
    "        \n",
    "        if fname != None:\n",
    "            Transform.write(result, 'transform_warp_'+fname, output)\n",
    "            \n",
    "        return result\n",
    "        \n",
    "    \n",
    "    \n",
    "    def process(img, fname=None, output=None, abs_thresh=(35, 105), hls_s_thresh=(180, 245),\n",
    "                hls_h_thresh=(20, 45), gray_thresh=(205, 255)):\n",
    "        \n",
    "        combined = Transform.combine([Transform.gray_threshold(img, fname=fname, output=output, thresh=gray_thresh),\n",
    "                                     Transform.abs_threshold(img, fname=fname, output=output, sobel_kernel=7, thresh=abs_thresh),\n",
    "                                     Transform.color_threshold(img, fname=fname, output=output, space='hls', select='s', thresh=hls_s_thresh),\n",
    "                                     Transform.color_threshold(img, fname=fname, output=output, space='hls', select='h', thresh=hls_h_thresh)],\n",
    "                                    fname=fname, output=output)\n",
    "        unwarped = Transform.unwarp(combined, fname=fname, output=output)\n",
    "        \n",
    "        return combined, unwarped\n",
    "    \n",
    "    \n",
    "    def test(files, output=None):\n",
    "           \n",
    "        output, figure, axes, fontsize, ncols = Util.set_output(len(files)*2, output)\n",
    "        counter=0\n",
    "        \n",
    "        for file in files:\n",
    "            \n",
    "            img = Transform.read(file)\n",
    "            abs_thresh = (35, 105)\n",
    "            hls_s_thresh = (180, 245)\n",
    "            hls_h_thresh = (20, 45)\n",
    "            gray_thresh = (205, 255)\n",
    "            \n",
    "            if output != 'inline' and output != 'qt' and output != None:\n",
    "                \n",
    "                name, ext = os.path.splitext(Util.get_fname(file))\n",
    "                Transform.abs_threshold(img, thresh=abs_thresh,\n",
    "                                        fname=name+'_x_3_'+str(abs_thresh[0])+'_'+str(abs_thresh[1])+ext,\n",
    "                                        output=output)\n",
    "                Transform.abs_threshold(img, sobel_kernel=5, thresh=abs_thresh,\n",
    "                                        fname=name+'_x_5_'+str(abs_thresh[0])+'_'+str(abs_thresh[1])+ext,\n",
    "                                        output=output)\n",
    "                Transform.abs_threshold(img, sobel_kernel=7, thresh=abs_thresh,\n",
    "                                        fname=name+'_x_7_'+str(abs_thresh[0])+'_'+str(abs_thresh[1])+ext,\n",
    "                                        output=output)\n",
    "                Transform.abs_threshold(img, orient='y', thresh=abs_thresh,\n",
    "                                        fname=name+'_y_3_'+str(abs_thresh[0])+'_'+str(abs_thresh[1])+ext,\n",
    "                                        output=output)\n",
    "                Transform.abs_threshold(img, orient='y', sobel_kernel=5, thresh=abs_thresh,\n",
    "                                        fname=name+'_y_5_'+str(abs_thresh[0])+'_'+str(abs_thresh[1])+ext,\n",
    "                                        output=output)\n",
    "                Transform.abs_threshold(img, orient='y', sobel_kernel=7, thresh=abs_thresh,\n",
    "                                        fname=name+'_y_7_'+str(abs_thresh[0])+'_'+str(abs_thresh[1])+ext,\n",
    "                                        output=output)\n",
    "                thresh = (30, 100)\n",
    "                Transform.mag_threshold(img, thresh=thresh,\n",
    "                                        fname=name+'_3_'+str(thresh[0])+'_'+str(thresh[1])+ext,\n",
    "                                        output=output)\n",
    "                Transform.mag_threshold(img, sobel_kernel=5, thresh=thresh,\n",
    "                                        fname=name+'_5_'+str(thresh[0])+'_'+str(thresh[1])+ext,\n",
    "                                        output=output)\n",
    "                Transform.mag_threshold(img, sobel_kernel=7, thresh=thresh,\n",
    "                                        fname=name+'_7_'+str(thresh[0])+'_'+str(thresh[1])+ext,\n",
    "                                        output=output)\n",
    "                thresh = (2/3, 4/3)            \n",
    "                Transform.dir_threshold(img, thresh=thresh,\n",
    "                                        fname=name+'_3_'+str(round(thresh[0], 2))+'_'+str(round(thresh[1],2))+ext,\n",
    "                                        output=output)\n",
    "                Transform.dir_threshold(img, sobel_kernel=5, thresh=thresh,\n",
    "                                        fname=name+'_5_'+str(round(thresh[0], 2))+'_'+str(round(thresh[1],2))+ext,\n",
    "                                        output=output)\n",
    "                Transform.dir_threshold(img, sobel_kernel=7, thresh=thresh,\n",
    "                                        fname=name+'_7_'+str(round(thresh[0], 2))+'_'+str(round(thresh[1],2))+ext,\n",
    "                                        output=output)\n",
    "                Transform.gray_threshold(img, thresh=gray_thresh,\n",
    "                                         fname=name+'_'+str(gray_thresh[0])+'_'+str(gray_thresh[1])+ext,\n",
    "                                         output=output)\n",
    "                Transform.color_threshold(img, space='hls', select='h', thresh=hls_h_thresh,\n",
    "                                          fname=name+'_'+str(hls_h_thresh[0])+'_'+str(hls_h_thresh[1])+ext,\n",
    "                                          output=output)\n",
    "                thresh = (90, 255)\n",
    "                Transform.color_threshold(img, space='hls', select='l', thresh=thresh,\n",
    "                                          fname=name+'_'+str(thresh[0])+'_'+str(thresh[1])+ext,\n",
    "                                          output=output)\n",
    "                Transform.color_threshold(img, space='hls', select='s', thresh=hls_s_thresh,\n",
    "                                          fname=name+'_'+str(hls_s_thresh[0])+'_'+str(hls_s_thresh[1])+ext,\n",
    "                                          output=output)\n",
    "                Transform.canny(img, kernel_size=5, fname=Util.get_fname(file), output=output)\n",
    "                \n",
    "            combined, unwarped = Transform.process(img, abs_thresh=abs_thresh, hls_s_thresh=hls_s_thresh,\n",
    "                                                   hls_h_thresh=hls_h_thresh, gray_thresh=gray_thresh,\n",
    "                                                   fname=Util.get_fname(file), output=output)\n",
    "            \n",
    "            if output == 'qt' or output == 'inline':\n",
    "                \n",
    "                axes[counter//ncols][counter%ncols].set_title(\"Combined Image\", fontsize=fontsize)\n",
    "                axes[counter//ncols][counter%ncols].imshow(combined, cmap='gray')\n",
    "                counter+=1\n",
    "                axes[counter//ncols][counter%ncols].set_title(\"Unwarped Image\", fontsize=fontsize)\n",
    "                axes[counter//ncols][counter%ncols].imshow(unwarped, cmap='gray')\n",
    "                counter+=1\n",
    "            \n",
    "        Util.show_output(output, figure, 'Transformed vs. Unwarped Test Images')\n",
    "            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Apply transformations on undistorted test images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob('output_images/transform*')\n",
    "for file in files:\n",
    "    os.remove(file)\n",
    "    \n",
    "files = glob.glob('output_images/undistort*')\n",
    "\n",
    "Transform.test(files, 'output_images')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Create line detection tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Line:\n",
    "    \n",
    "    \n",
    "    def __init__(self, nwindows=9, margin=150, minpix=50, n=5):\n",
    "        \n",
    "        self.nwindows = nwindows\n",
    "        self.margin = margin\n",
    "        self.minpix = minpix\n",
    "        self.n = n\n",
    "        \n",
    "        # was the line detected in the last iteration?\n",
    "        self.detected = False\n",
    "        # x values of the last n fits of the line\n",
    "        self.recent_xfitted = []\n",
    "        #average x values of the fitted line over the last n iterations\n",
    "        self.bestx = None\n",
    "        #polynomial coefficients averaged over the last n iterations\n",
    "        self.best_fit = None\n",
    "        #polynomial coefficients for the most recent fit\n",
    "        self.current_fit = []\n",
    "        #radius of curvature of the line in some units\n",
    "        self.radius_of_curvature = None\n",
    "        #distance in meters of vehicle center from the line\n",
    "        self.line_base_pos = None\n",
    "        #difference in fit coefficients between last and new fits\n",
    "        #self.diffs = np.array([0,0,0], dtype='float') # Not used in this project\n",
    "        #x values for detected line pixels\n",
    "        self.allx = None                                                    \n",
    "        #y values for detected line pixels\n",
    "        self.ally = None                                                    \n",
    "        \n",
    "        self.ploty = []\n",
    "        \n",
    "        \n",
    "    def init(self, binary, base = None):\n",
    "        \n",
    "        self.binary = binary\n",
    "        if base != None:\n",
    "            self.line_base_pos = base\n",
    "        \n",
    "        \n",
    "    def find_pixels(self):\n",
    "        \n",
    "        # Set height of windows - based on nwindows above and image shape\n",
    "        window_height = np.int(self.binary.shape[0]//self.nwindows)\n",
    "        \n",
    "        # Identify the x and y positions of all nonzero pixels in the image\n",
    "        nonzero = self.binary.nonzero()\n",
    "        nonzeroy = np.array(nonzero[0])\n",
    "        nonzerox = np.array(nonzero[1])\n",
    "        \n",
    "        # Current positions to be updated later for each window in nwindows\n",
    "        current = self.line_base_pos\n",
    "\n",
    "        # Create empty lists to receive left and right lane pixel indices\n",
    "        inds = []\n",
    "\n",
    "        # Step through the windows one by one\n",
    "        for window in range(self.nwindows):\n",
    "            \n",
    "            # Identify window boundaries in x and y (and right and left)\n",
    "            win_y_low = self.binary.shape[0] - (window + 1) * window_height\n",
    "            win_y_high = self.binary.shape[0] - window * window_height\n",
    "            win_x_low = current - self.margin\n",
    "            win_x_high = current + self.margin\n",
    "        \n",
    "            ### Identify the nonzero pixels in x and y within the window ###\n",
    "            good_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & \n",
    "                         (nonzerox >= win_x_low) &  (nonzerox < win_x_high)).nonzero()[0]\n",
    "\n",
    "            # Append these indices to the lists\n",
    "            inds.append(good_inds)\n",
    "        \n",
    "            if len(good_inds) > self.minpix:\n",
    "                current = np.int(np.mean(nonzerox[good_inds]))\n",
    "\n",
    "        inds = np.concatenate(inds)\n",
    "\n",
    "        # Extract left and right line pixel positions\n",
    "        if len(inds) > self.minpix*self.nwindows//2:\n",
    "            self.allx = nonzerox[inds]\n",
    "            self.ally = nonzeroy[inds] \n",
    "            self.detected = False\n",
    "        else:\n",
    "            self.detected = True\n",
    "            \n",
    "        return self.detected\n",
    "    \n",
    "    \n",
    "    def fit_polynomial(self):\n",
    "\n",
    "        if len(self.current_fit) > self.n:\n",
    "            self.current_fit = self.current_fit[1:]\n",
    "        self.current_fit.append(np.polyfit(self.ally, self.allx, 2))\n",
    "        \n",
    "        self.best_fit = pd.DataFrame(self.current_fit).mean().values\n",
    "\n",
    "        # Generate x and y values for plotting\n",
    "        ploty = np.linspace(0, self.binary.shape[0]-1, self.binary.shape[0] )\n",
    "        try:\n",
    "            fitx = self.best_fit[0]*ploty**2 + self.best_fit[1]*ploty + self.best_fit[2]\n",
    "        except TypeError:\n",
    "            # Avoids an error if `left` and `right_fit` are still none or incorrect\n",
    "            print('The function failed to fit a line!')\n",
    "            fitx = 1*ploty**2 + 1*ploty\n",
    "        \n",
    "        if len(self.recent_xfitted) > self.n:\n",
    "            self.recent_xfitted = self.recent_xfitted[1:]\n",
    "        self.recent_xfitted.append(fitx)\n",
    "        self.bestx = pd.DataFrame(self.recent_xfitted).mean().values.astype(int)\n",
    "        self.ploty = ploty    \n",
    "        \n",
    "        return self.bestx, ploty\n",
    "    \n",
    "    \n",
    "    def search_around_poly(self, binary):\n",
    "\n",
    "        # Grab activated pixels\n",
    "        nonzero = binary.nonzero()\n",
    "        nonzeroy = np.array(nonzero[0])\n",
    "        nonzerox = np.array(nonzero[1])\n",
    "    \n",
    "        poly = (self.best_fit[0]*nonzeroy**2 + self.best_fit[1]*nonzeroy + self.best_fit[2])\n",
    "        inds = ((nonzerox >= poly - self.margin) & (nonzerox < poly + self.margin)).nonzero()[0]\n",
    "        \n",
    "        if len(inds) > self.minpix*self.nwindows//2:\n",
    "            # Again, extract left and right line pixel positions\n",
    "            self.allx = nonzerox[inds]\n",
    "            self.ally = nonzeroy[inds] \n",
    "            self.detected = True\n",
    "        else:\n",
    "            self.detected = False\n",
    "\n",
    "        # Fit new polynomials\n",
    "        return self.detected, self.fit_polynomial()\n",
    "    \n",
    "    \n",
    "    def get_curvature_radius(self, xm_per_pix):\n",
    "        \n",
    "        y_eval = np.max(self.ploty)\n",
    "        #ym_per_pix = 30/720\n",
    "        # This project uses smaller field of view so the y dimension is smaller as well\n",
    "        ym_per_pix = 20/720 # meters per pixel in y dimension\n",
    "\n",
    "        # Fit new polynomials to x,y in world space\n",
    "        fit_cr = np.polyfit(self.ploty*ym_per_pix, self.bestx*xm_per_pix, 2)\n",
    "        # Calculate the new radii of curvature\n",
    "        self.radius_of_curvature = ((1 + (2*fit_cr[0]*y_eval*ym_per_pix + fit_cr[1])**2)**1.5) / np.absolute(2*fit_cr[0])\n",
    " \n",
    "        # Now our radius of curvature is in meters\n",
    "        return self.radius_of_curvature\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Create lane detection tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LaneDetector:\n",
    "    \n",
    "    \n",
    "    def __init__(self, camera, left_line, right_line, output=None):\n",
    "        \n",
    "        self.camera = camera\n",
    "        self.left_line = left_line\n",
    "        self.right_line = right_line\n",
    "        self.leftx_base = None\n",
    "        self.rightx_base = None\n",
    "        self.output = output\n",
    "        self.counter = 0\n",
    "        #self.left_not_detected = 0\n",
    "        #self.right_not_detected = 0\n",
    "        #self.left_fitx = []\n",
    "        #self.right_fitx = []\n",
    "        #self.ploty = []\n",
    "        \n",
    "        \n",
    "    def read_binary(fname):\n",
    "        \n",
    "        return cv2.imread(fname)[:,:,0]//255\n",
    "    \n",
    "    \n",
    "    def find_lane_start(binary):\n",
    "        \n",
    "        histogram = np.sum(binary[binary.shape[0]//2:,:], axis=0)\n",
    "        midpoint = np.int(histogram.shape[0]//2)\n",
    "        leftx_base = np.argmax(histogram[:midpoint])\n",
    "        rightx_base = np.argmax(histogram[midpoint:]) + midpoint\n",
    "        \n",
    "        return leftx_base, rightx_base\n",
    "    \n",
    "    \n",
    "    def process(self, img):\n",
    "        \n",
    "        img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "        if self.output != None:\n",
    "            fname = '{:08d}.jpg'.format(self.counter)\n",
    "        else:\n",
    "            fname = None\n",
    "        _, image = self.camera.undistort(img=img, fname=fname, output=self.output)\n",
    "        #_, image = self.camera.undistort(img=img)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        _, binary = Transform.process(image, fname=fname, output=self.output)\n",
    "        #_, binary = Transform.process(image)\n",
    "\n",
    "        if self.leftx_base == None or self.rightx_base == None:\n",
    "            self.leftx_base, self.rightx_base = LaneDetector.find_lane_start(binary)\n",
    "            self.left_line.init(binary, self.leftx_base)\n",
    "            self.right_line.init(binary, self.rightx_base)\n",
    "            left_detected = self.left_line.find_pixels()\n",
    "            right_detected = self.right_line.find_pixels()\n",
    "            #if left_detected == True:\n",
    "            #    self.left_fitx, self.ploty = self.left_line.fit_polynomial()\n",
    "            left_fitx, ploty = self.left_line.fit_polynomial()\n",
    "            #if right_detected == True:\n",
    "            #    self.right_fitx, self.ploty = self.right_line.fit_polynomial()\n",
    "            right_fitx, ploty = self.right_line.fit_polynomial()\n",
    "        else:\n",
    "            left_detected, (left_fitx, ploty) = self.left_line.search_around_poly(binary)\n",
    "            #if left_detected == False:\n",
    "            #    self.left_not_detected += 1\n",
    "            #else:\n",
    "            #    self.left_fitx = left_fitx\n",
    "            #    self.ploty = ploty\n",
    "            #    self.left_not_detected = 0\n",
    "            #if self.left_not_detected > 3:\n",
    "            #    self.leftx_base = None\n",
    "            right_detected, (right_fitx, ploty) = self.right_line.search_around_poly(binary)\n",
    "            #if right_detected == False:\n",
    "            #    self.right_not_detected += 1\n",
    "            #else:\n",
    "            #    self.right_fitx = right_fitx\n",
    "            #    self.ploty = ploty\n",
    "            #    self.right_not_detected = 0\n",
    "            #if self.right_not_detected > 3:\n",
    "            #    self.rightx_base = None\n",
    "            \n",
    "        # Create an image to draw the lines on\n",
    "        warp_zero = np.zeros_like(binary).astype(np.uint8)\n",
    "        color_warp = np.dstack((warp_zero, warp_zero, warp_zero))        \n",
    "        \n",
    "        # Recast the x and y points into usable format for cv2.fillPoly()\n",
    "        pts_left = np.array([np.transpose(np.vstack([left_fitx, ploty]))])\n",
    "        pts_right = np.array([np.flipud(np.transpose(np.vstack([right_fitx, ploty])))])\n",
    "        pts = np.hstack((pts_left, pts_right))\n",
    "\n",
    "        # Draw the lane onto the warped blank image\n",
    "        cv2.fillPoly(color_warp, np.int_([pts]), (0,255, 0))\n",
    "        \n",
    "        warp = Transform.warp(color_warp)\n",
    "        \n",
    "        # Combine the result with the original image\n",
    "        result = cv2.addWeighted(image, 1, warp, 0.3, 0)\n",
    "        \n",
    "        # Width of lane in pixels\n",
    "        lane_width_in_pix = right_fitx[len(ploty)-1]-left_fitx[len(ploty)-1]\n",
    "        xm_per_pix = 3.7/lane_width_in_pix\n",
    "        \n",
    "        curverad = int(np.mean([self.left_line.get_curvature_radius(xm_per_pix),\n",
    "                                self.right_line.get_curvature_radius(xm_per_pix)]))\n",
    "        \n",
    "        cv2.putText(result, \"The lane curvature radius is {}m.\".format(curverad), (100, 50),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
    "        \n",
    "        center = round(3.7*((left_fitx[len(ploty)-1]+right_fitx[len(ploty)-1])//2-image.shape[1]//2)/lane_width_in_pix,2)\n",
    "        \n",
    "        if center > 0:\n",
    "            msg = \"The car is located {:.2f}m to the left from the center of the lane.\".format(center)\n",
    "        elif center < 0:\n",
    "            msg = \"The car is located {:.2f}m to the right from the center of the lane.\".format(abs(center))\n",
    "        else:\n",
    "            msg = \"The car is located at the center of the lane.\"\n",
    "        \n",
    "        cv2.putText(result, msg, (100, 100), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
    "\n",
    "        if self.output != None and self.output != '' and self.output[-1] != '/':\n",
    "            self.output += '/'\n",
    "            \n",
    "        if self.output != None:\n",
    "            cv2.imwrite(self.output+fname, cv2.cvtColor(result, cv2.COLOR_BGR2RGB))\n",
    "            \n",
    "        self.counter += 1\n",
    "        \n",
    "        return result\n",
    "        \n",
    "        \n",
    "    def test(files, output=None):\n",
    "        \n",
    "        output, figure, axes, fontsize, ncols = Util.set_output(len(files), output)\n",
    "        counter = 0\n",
    "        \n",
    "        for file in files:\n",
    "            binary = LaneDetector.read_binary(file)\n",
    "            leftx_base, rightx_base = LaneDetector.find_lane_start(binary)\n",
    "            left_line = Line()\n",
    "            left_line.init(binary, leftx_base)\n",
    "            left_line.find_pixels()\n",
    "            left_fitx, ploty = left_line.fit_polynomial()\n",
    "            right_line = Line()\n",
    "            right_line.init(binary, rightx_base)\n",
    "            right_line.find_pixels()\n",
    "            right_fitx, ploty = right_line.fit_polynomial()\n",
    "            \n",
    "            if output == 'qt' or output == 'inline':\n",
    "                \n",
    "                axes[counter//ncols][counter%ncols].set_title(\"Detected Lane\", fontsize=fontsize)\n",
    "                axes[counter//ncols][counter%ncols].imshow(binary, cmap='gray')\n",
    "                axes[counter//ncols][counter%ncols].plot(left_fitx, ploty, color='green')\n",
    "                axes[counter//ncols][counter%ncols].plot(right_fitx, ploty, color='green')\n",
    "                counter+=1\n",
    "                \n",
    "            elif output != None:\n",
    "                \n",
    "                out_img = np.dstack((binary, binary, binary))*255\n",
    "                pts_left = np.array([np.transpose(np.vstack([left_fitx, ploty]))])\n",
    "                pts_right = np.array([np.flipud(np.transpose(np.vstack([right_fitx, ploty])))])\n",
    "                cv2.polylines(out_img, np.int_([pts_left]), False, (0,255, 0), thickness=3)\n",
    "                cv2.polylines(out_img, np.int_([pts_right]), False, (0,255, 0), thickness=3)\n",
    "                cv2.imwrite(output+'detect_'+Util.get_fname(file), out_img) \n",
    "        \n",
    "        Util.show_output(output, figure, 'Detected Lanes')\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Detect lanes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob('output_images/detect*')\n",
    "for file in files:\n",
    "    os.remove(file)\n",
    "\n",
    "files = glob.glob('output_images/transform_unwarp*')\n",
    "\n",
    "LaneDetector.test(files, 'output_images')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Test short video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "t:   0%|          | 0/25 [00:00<?, ?it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video output_videos/short_project_video.mp4.\n",
      "Moviepy - Writing video output_videos/short_project_video.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready output_videos/short_project_video.mp4\n",
      "CPU times: user 6.24 s, sys: 361 ms, total: 6.6 s\n",
      "Wall time: 6.12 s\n"
     ]
    }
   ],
   "source": [
    "detector = LaneDetector(Camera(), Line(), Line(), 'output_videos')\n",
    "\n",
    "video = 'project_video.mp4'\n",
    "video_output = 'output_videos/short_'+video\n",
    "\n",
    "files = glob.glob('output_videos/*.jpg')\n",
    "for file in files:\n",
    "    os.remove(file)\n",
    "\n",
    "if os.path.isfile(video_output):\n",
    "    os.remove(video_output)\n",
    "\n",
    "short_clip = VideoFileClip(video).subclip(0,1)\n",
    "short_clip_output = short_clip.fl_image(detector.process)\n",
    "%time short_clip_output.write_videofile(video_output, audio=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11. Test project video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "t:   0%|          | 0/1260 [00:00<?, ?it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video output_videos/project_video.mp4.\n",
      "Moviepy - Writing video output_videos/project_video.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready output_videos/project_video.mp4\n",
      "CPU times: user 4min 36s, sys: 5.36 s, total: 4min 41s\n",
      "Wall time: 3min 45s\n"
     ]
    }
   ],
   "source": [
    "detector = LaneDetector(Camera(), Line(), Line())\n",
    "\n",
    "video = 'project_video.mp4'\n",
    "video_output = 'output_videos/'+video\n",
    "\n",
    "if os.path.isfile(video_output):\n",
    "    os.remove(video_output)\n",
    "\n",
    "clip = VideoFileClip(video)\n",
    "clip_output = clip.fl_image(detector.process)\n",
    "%time clip_output.write_videofile(video_output, audio=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12. See the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"960\" height=\"540\" controls>\n",
       "  <source src=\"output_videos/project_video.mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(video_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
